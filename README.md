## Transcriber ‚Äì Assistant vocal en ligne

### üöÄ Objectif
Application web qui :
- **√©coute ta voix en direct dans le navigateur**,
- **transcrit** ce que tu dis (Whisper),
- **r√©sume** chaque morceau,
- **g√©n√®re des questions intelligentes** pour approfondir,
- **construit un compte‚Äërendu structur√© en temps r√©el** (projets, t√¢ches, d√©cisions, etc.).

Tout se fait **en ligne depuis le navigateur**, le serveur ne d√©pend pas du micro local de la machine serveur.

---

### üß± Architecture
- `index.html`  
  - UI moderne : boutons D√©marrer/Arr√™ter, panneaux Transcriptions / Analyses / Compte‚Äërendu.  
  - Utilise `getUserMedia` + `AudioContext` (16 kHz) pour **capturer le micro c√¥t√© navigateur**.  
  - Envoie en continu des chunks audio PCM Float32 via **Socket.IO** (`audio_chunk`) au serveur.

- `app.py`  
  - Serveur **Flask + Flask‚ÄëSocketIO**.  
  - √âv√©nements Socket.IO :
    - `start_recording` : d√©marre une nouvelle session, r√©initialise les donn√©es.
    - `audio_chunk` : re√ßoit les buffers audio du navigateur, lance la transcription/analysis en thread.
    - `stop_recording` : stoppe la session et renvoie le statut final.  
  - Utilise :
    - `transcribe.transcribe_chunk` pour la **transcription Whisper**,
    - `gpt_pipeline.summarise_and_question` pour le **r√©sum√© + questions**,
    - `report_generator.generate_live_report` pour le **compte‚Äërendu JSON structur√©**.  
  - Diffuse en temps r√©el au front :
    - `transcription` : texte brut + timecodes,
    - `analysis` : r√©sum√© + liste de questions,
    - `live_report` : objet JSON structur√©.

- `transcribe.py`  
  - Charge le mod√®le Whisper (`small` par d√©faut).  
  - Re√ßoit un `np.array` audio + sample rate navigateur.  
  - **Normalise et resample automatiquement en 16 kHz** pour Whisper.  
  - Retourne les `segments` de Whisper (`start`, `end`, `text`).

- `gpt_pipeline.py`  
  - Appelle l‚ÄôAPI OpenAI (`gpt-4o`) pour :
    - r√©sumer un chunk de texte en **une phrase**,
    - g√©n√©rer **2 questions** pertinentes.  
  - Retourne une r√©ponse texte multi‚Äëligne que `app.py` d√©coupe en `summary` + `questions`.

- `report_generator.py`  
  - Appelle l‚ÄôAPI OpenAI (`gpt-4o`) pour analyser tout le texte accumul√© et produire un **JSON strict** :
    - `projets`, `dates`, `taches`, `personnes`, `chiffres`, `decisions`, `points_cles`, `points`, `nombre de mots`.  
  - `app.py` nettoie la r√©ponse (retire les ```json √©ventuels) puis parse le JSON et l‚Äôenvoie au front sous forme d‚Äô√©v√©nement `live_report`.

- `session.json`  
  - Sauvegarde locale de la session (liste de segments : texte, r√©sum√©, questions).

- `requirements.txt`  
  - Libs principales :  
    - `git+https://github.com/openai/whisper.git`  
    - `torch`, `torchaudio`  
    - `openai`, `python-dotenv`  
    - `numpy`  
    - `flask`, `flask-socketio`, `eventlet`

---

### ‚öôÔ∏è Configuration requise
- **Python recommand√© : 3.11**  
  (√âvite les versions exp√©rimentales comme 3.14 pour Whisper & co.)
- Variable d‚Äôenvironnement :
  - `OPENAI_API_KEY` : cl√© OpenAI avec acc√®s aux mod√®les `gpt-4o`.

Sur ton poste local :
```bash
export OPENAI_API_KEY="ta_cle"
```

Sur un h√©bergeur (Render, Railway, etc.) :
- Ajoute `OPENAI_API_KEY` dans les **variables d‚Äôenvironnement** du service.

---

### ‚ñ∂Ô∏è Lancer en local (optionnel)
Dans le dossier du projet :

```bash
pip install -r requirements.txt
export OPENAI_API_KEY="ta_cle"
python app.py
```

Puis ouvre dans ton navigateur :
- `http://localhost:5000`

La page te demandera l‚Äôacc√®s au **micro**.  
Quand tu cliques sur **D√©marrer** :
- le front envoie tes chunks audio au serveur,
- le serveur transcrit, r√©sume, pose des questions,
- le compte‚Äërendu se met √† jour en direct.

---

### üåê Mise en ligne (d√©ploiement)
Plusieurs options :

#### 1. H√©bergement type Render / Railway
1. Pousser ce repo sur GitHub (`hvmedx/Transcriber`).  
2. Cr√©er un nouveau service web sur la plateforme choisie en pointant sur ce repo.  
3. Configurer :
   - **Build command** :  
     `pip install -r requirements.txt`
   - **Start command** :  
     `python app.py`
   - **Env** : `OPENAI_API_KEY`.
4. La plateforme expose ensuite une URL publique (HTTPS).

#### 2. Docker (optionnel)
Exemple de `Dockerfile` minimal :

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
ENV OPENAI_API_KEY=changeme
EXPOSE 5000
CMD ["python", "app.py"]
```

Build & run :
```bash
docker build -t transcriber .
docker run -p 5000:5000 -e OPENAI_API_KEY="ta_cle" transcriber
```

---

### üß™ Fonctionnalit√©s actuelles
- **Transcription en direct** (fran√ßais, via Whisper).
- **R√©sum√©s automatiques** par segment.
- **Questions de relance** pour approfondir ce que tu dis au fur et √† mesure.
- **Compte‚Äërendu structur√© en temps r√©el** (projets, t√¢ches, d√©cisions, etc.).
- **Interface web moderne** avec trois panneaux :
  - Transcriptions,
  - Analyses & Questions,
  - Compte Rendu en Temps R√©el.

---

### ‚úÖ Roadmap possible
- Support multilingue (d√©tection automatique de la langue).
- Export du compte‚Äërendu (PDF / Markdown / Notion).
- Gestion multi‚Äëutilisateurs / authentification.
- Passage de l‚Äôaudio en binaire (WebSocket + ArrayBuffer) pour optimiser la bande passante.


